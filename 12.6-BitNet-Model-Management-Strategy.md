# 12.6 🤖 Estratégia de Gerenciamento do Modelo BitNet

**Objetivo**: Definir um ciclo de vida claro e robusto para o modelo BitNet local (quantização 4-bit) utilizado pelo `summarize_scene.py`, incluindo versionamento, implantação de atualizações, rollback e monitoramento.

**Status Atual no Checklist**: `| Estratégia de Gerenciamento do Modelo BitNet | 📝 Ação Requerida |`

---

## 1. Visão Geral e Justificativa

O modelo BitNet é um componente crítico da inteligência do `VV-Video-AI-System`, responsável pela interpretação semântica e sumarização de cenas. Atualmente, o `bootstrap.py` "clona o modelo BitNet local se ausente". Para um sistema em produção e em evolução, uma abordagem mais estruturada para o gerenciamento deste modelo é necessária para garantir consistência, rastreabilidade, e a capacidade de atualizar ou reverter o modelo de forma controlada.

Uma estratégia de gerenciamento de modelo (ModelOps ou MLOps) abrange como os modelos de machine learning são versionados, testados, implantados e monitorados.

## 2. Componentes da Estratégia de Gerenciamento do Modelo

### 2.1. Versionamento do Modelo

*   **Importância**: Permite rastrear qual versão do modelo está em uso, facilitando a depuração, a reprodução de resultados e o rollback para versões anteriores.
*   **Opções**:
    1.  **Git LFS (Large File Storage)**:
        *   **Descrição**: Se o arquivo do modelo (ou arquivos) for grande, o Git LFS permite versionar arquivos grandes no Git sem sobrecarregar o repositório principal. O arquivo do modelo em si é armazenado em um servidor LFS, enquanto o repositório Git armazena ponteiros para ele.
        *   **Implementação**:
            *   Instalar Git LFS: `git lfs install`
            *   Rastrear os arquivos do modelo: `git lfs track "*.bin"` (ou o padrão de arquivo do seu modelo BitNet).
            *   Adicionar `.gitattributes` (criado pelo comando track) ao Git.
            *   O `bootstrap.py` precisaria garantir que `git lfs pull` seja executado após o clone/pull do repositório do modelo.
        *   **Vantagens**: Integração com o fluxo Git; o versionamento do modelo acompanha o versionamento do código que o utiliza (se no mesmo repo ou como submódulo).
        *   **Desvantagens**: Requer um servidor LFS (GitHub oferece gratuitamente com limites, GitLab também).
    2.  **Registro de Modelos Dedicado (Model Registry)**:
        *   **Descrição**: Plataformas como MLflow Model Registry, DVC (Data Version Control), ou mesmo um sistema de versionamento simples baseado em armazenamento em nuvem (e.g., S3 com versionamento habilitado) e um arquivo de manifesto.
        *   **Implementação**:
            *   O modelo é treinado/convertido e depois "registrado" com um número de versão e, opcionalmente, metadados (métricas de performance, parâmetros de treinamento).
            *   O `bootstrap.py` consultaria o registro para buscar a versão "production" ou uma versão específica do modelo.
        *   **Vantagens**: Mais robusto para MLOps, desacopla o modelo do código, permite metadados ricos e gerenciamento de estágios (staging, production, archived).
        *   **Desvantagens**: Adiciona complexidade e potencialmente novas ferramentas ao stack.
    3.  **Checksums e Arquivo de Manifesto Simples**:
        *   **Descrição**: Armazenar os arquivos do modelo em um local acessível (e.g., HTTP, S3 público/privado). No repositório do `VV-Video-AI-System`, manter um arquivo de manifesto (e.g., `model_manifest.json`) que especifica a URL de download e o checksum (SHA256) da versão atual do modelo.
        *   **Implementação**:
            ```json name=model_manifest.json.example
            {
              "model_name": "BitNet-4bit-Summarizer",
              "version": "1.2.0",
              "url": "https://example.com/models/bitnet-v1.2.0.tar.gz",
              "sha256": "abcdef123456...",
              "description": "Modelo BitNet quantizado 4-bit para sumarização de cenas, treinado em YYYY-MM-DD."
            }
            ```
            O `bootstrap.py` leria este manifesto, baixaria o modelo se diferente do local (verificando o checksum), e validaria a integridade.
        *   **Vantagens**: Relativamente simples de implementar, controle explícito da versão via manifesto.
        *   **Desvantagens**: Menos automatizado para "promover" modelos; requer atualização manual do manifesto.

*   **Recomendação Inicial**: Começar com **Checksums e Arquivo de Manifesto Simples** pela sua simplicidade e controle explícito. Se as necessidades de MLOps crescerem, migrar para Git LFS ou um registro de modelos dedicado.

### 2.2. Armazenamento e Distribuição do Modelo

*   **Onde Armazenar**:
    *   **Servidor HTTP/HTTPS**: Simples para download.
    *   **Cloud Storage (S3, Google Cloud Storage, Azure Blob Storage)**: Escalável, confiável, controle de acesso.
    *   **Dentro do Repositório (se pequeno o suficiente ou com Git LFS)**.
*   **Formato**: Idealmente, um arquivo compactado (e.g., `.tar.gz`) contendo todos os artefatos do modelo (pesos, configuração, vocabulário, etc.).

### 2.3. Atualização do Modelo (`bootstrap.py` e/ou Script Dedicado)

O `bootstrap.py` (ou um script dedicado `update_model.py`) seria responsável por:

1.  **Ler o Manifesto**: Obter a URL e o checksum da versão desejada do modelo.
2.  **Verificar Versão Local**:
    *   Comparar o checksum do modelo local (se existir) com o checksum do manifesto.
    *   Armazenar um pequeno arquivo local com o checksum/versão do modelo atualmente instalado (e.g., `/opt/vv-video-ai-system/models/.current_model_version`).
3.  **Download e Validação**:
    *   Se o modelo local estiver desatualizado ou ausente, baixar o novo modelo do URL especificado.
    *   Verificar o checksum do arquivo baixado contra o checksum no manifesto. Se não corresponder, abortar e alertar.
4.  **Instalação**:
    *   Descompactar e instalar o modelo no local esperado por `summarize_scene.py` (e.g., `/opt/vv-video-ai-system/models/bitnet/`).
    *   Atualizar o arquivo `.current_model_version` local.
5.  **Notificação/Reinício**:
    *   Opcionalmente, notificar o serviço `scene_summarizer` para recarregar o modelo (se ele suportar hot-reloading) ou sinalizar que um reinício do container `scene_summarizer` é necessário para usar o novo modelo. Se o modelo é carregado na inicialização do script `summarize_scene.py`, um reinício do container é a forma mais simples.

### 2.4. Rollback do Modelo

*   **Estratégia**:
    1.  Manter versões anteriores do `model_manifest.json` no controle de versão do Git.
    2.  Para fazer rollback, reverter para um commit anterior do `model_manifest.json` que aponte para uma versão estável do modelo.
    3.  Executar novamente o `bootstrap.py` ou `update_model.py` no(s) host(s) para que baixem e instalem a versão anterior.
    4.  Alternativamente, se os arquivos de modelo antigos forem mantidos no servidor de download, o manifesto pode ser atualizado para apontar para a URL da versão estável mais antiga.

### 2.5. Teste de Novos Modelos

*   **Ambiente de Staging**: Antes de atualizar o `model_manifest.json` na branch `main` (produção), um novo modelo deve ser testado em um ambiente de staging.
*   **Métricas de Avaliação**: Definir métricas para avaliar a performance do novo modelo (e.g., qualidade da sumarização, tempo de inferência, uso de recursos) em comparação com o modelo atual.
*   **Testes A/B (Avançado)**: Para sistemas com alto volume, considerar testes A/B onde uma pequena porcentagem do tráfego é direcionada para o novo modelo para comparar sua performance em produção.

### 2.6. Monitoramento da Performance do Modelo

*   **Coletar Métricas**: O script `summarize_scene.py` deve logar:
    *   Tempo de inferência por cena.
    *   Uso de CPU/GPU durante a inferência (se possível).
    *   Taxas de erro ou exceções durante o carregamento ou inferência do modelo.
*   **Feedback Loop**: Implementar um mecanismo (mesmo que manual inicialmente) para coletar feedback sobre a qualidade das sumarizações geradas. Este feedback pode ser usado para decidir quando treinar/fine-tune um novo modelo.

## 3. Modificações Sugeridas

### 3.1. `model_manifest.json` (Exemplo)

Colocar em `/opt/vv-video-ai-system/model_manifest.json` (e versionado no Git).

```json name=model_manifest.json
{
  "model_name": "BitNet-4bit-Summarizer",
  "version": "1.0.0",
  "release_date": "2025-05-01",
  "description": "Versão inicial do modelo BitNet quantizado 4-bit para sumarização de cenas.",
  "artifacts": [
    {
      "filename": "bitnet_summarizer_v1.0.0.tar.gz",
      "url": "https://your-storage.example.com/models/bitnet_summarizer_v1.0.0.tar.gz",
      "sha256": "sha256_hash_of_the_tar_gz_file",
      "size_bytes": 123456789,
      "target_path_in_container": "/app/models/bitnet"
    }
  ],
  "notes": "Usar este modelo com summarize_scene.py versão >= 2.1"
}

3.2. Atualizações em bootstrap.py
Python
import json
import hashlib
import tarfile
import requests # Para download
from pathlib import Path
import shutil
import logging # Assumindo logging configurado

MODEL_MANIFEST_PATH = Path("/opt/vv-video-ai-system/model_manifest.json") # Ou de onde for carregado
MODELS_INSTALL_DIR = Path("/opt/vv-video-ai-system/models") # Diretório base para modelos
CURRENT_MODEL_INFO_FILE = MODELS_INSTALL_DIR / ".current_model_info.json"

def calculate_sha256(filepath: Path) -> str:
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def download_file(url: str, destination: Path, expected_sha256: str):
    logging.info(f"Baixando modelo de {url} para {destination}...")
    destination.parent.mkdir(parents=True, exist_ok=True)
    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(destination, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        
        downloaded_sha256 = calculate_sha256(destination)
        if downloaded_sha256 != expected_sha256:
            logging.error(f"Checksum do modelo baixado ({downloaded_sha256}) não corresponde ao esperado ({expected_sha256}) para {url}.")
            destination.unlink() # Remover arquivo corrompido
            return False
        logging.info(f"Modelo baixado com sucesso e checksum verificado: {destination.name}")
        return True
    except requests.exceptions.RequestException as e:
        logging.error(f"Erro ao baixar o modelo de {url}: {e}")
        if destination.exists():
            destination.unlink()
        return False

def install_model_artifact(tar_gz_path: Path, target_path_str: str, model_version: str):
    # target_path_str é relativo ao container, mas aqui vamos usar um path absoluto no host
    # que será montado no container.
    # Ex: se target_path_in_container for "/app/models/bitnet", e o volume for
    # ./models:/app/models, então o target_path real no host é MODELS_INSTALL_DIR / "bitnet"
    
    # O nome do diretório do modelo pode ser derivado do nome do artefato ou especificado
    model_base_name = Path(target_path_str).name # e.g., "bitnet"
    install_path = MODELS_INSTALL_DIR / model_base_name
    
    logging.info(f"Instalando artefato do modelo {tar_gz_path.name} em {install_path}...")
    if install_path.exists():
        logging.info(f"Removendo instalação anterior do modelo em {install_path}.")
        shutil.rmtree(install_path)
    install_path.mkdir(parents=True, exist_ok=True)

    try:
        with tarfile.open(tar_gz_path, "r:gz") as tar:
            tar.extractall(path=install_path)
        logging.info(f"Modelo {tar_gz_path.name} instalado com sucesso em {install_path}.")
        # Guardar informação do modelo instalado
        with open(CURRENT_MODEL_INFO_FILE, "w") as f:
            json.dump({"version": model_version, "model_name": model_base_name, "artifact_file": tar_gz_path.name}, f)
        return True
    except tarfile.TarError as e:
        logging.error(f"Erro ao extrair o modelo {tar_gz_path.name}: {e}")
        if install_path.exists():
            shutil.rmtree(install_path) # Limpar instalação parcial
        return False
    finally:
        if tar_gz_path.exists(): # Remover o tar.gz baixado após a instalação
             tar_gz_path.unlink()


def setup_bitnet_model():
    logging.info("Configurando modelo BitNet...")
    if not MODEL_MANIFEST_PATH.exists():
        logging.error(f"Arquivo de manifesto do modelo não encontrado em {MODEL_MANIFEST_PATH}")
        return False

    with open(MODEL_MANIFEST_PATH, "r") as f:
        manifest = json.load(f)

    model_version_manifest = manifest.get("version")
    model_name_manifest = manifest.get("model_name")
    logging.info(f"Manifesto carregado para o modelo: {model_name_manifest}, Versão: {model_version_manifest}")

    current_model_info = {}
    if CURRENT_MODEL_INFO_FILE.exists():
        with open(CURRENT_MODEL_INFO_FILE, "r") as f:
            try:
                current_model_info = json.load(f)
            except json.JSONDecodeError:
                logging.warning(f"Não foi possível ler o arquivo de informação do modelo atual: {CURRENT_MODEL_INFO_FILE}")
    
    # Verifica se o modelo e versão do manifesto já estão instalados
    if current_model_info.get("version") == model_version_manifest and \
       current_model_info.get("model_name") == Path(manifest["artifacts"][0]["target_path_in_container"]).name : # Simplificado para um artefato
        # Adicionalmente, verificar se os arquivos realmente existem no target_path
        expected_install_dir = MODELS_INSTALL_DIR / Path(manifest["artifacts"][0]["target_path_in_container"]).name
        if expected_install_dir.exists() and any(expected_install_dir.iterdir()):
             logging.info(f"Modelo {model_name_manifest} versão {model_version_manifest} já está instalado e atualizado.")
             return True
        else:
            logging.warning(f"Informação do modelo atual indica versão {model_version_manifest}, mas os arquivos não foram encontrados em {expected_install_dir}. Prosseguindo com a instalação.")


    # Processar cada artefato no manifesto (geralmente um para o modelo BitNet)
    for artifact in manifest.get("artifacts", []):
        filename = artifact["filename"]
        url = artifact["url"]
        expected_sha256 = artifact["sha256"]
        target_path_in_container = artifact["target_path_in_container"] # Usado para derivar o nome do subdiretório do modelo

        download_destination = MODELS_INSTALL_DIR / filename
        
        # Lógica de download (pode ser mais robusta, com retries, etc.)
        if not download_file(url, download_destination, expected_sha256):
            logging.error(f"Falha ao baixar o artefato do modelo: {filename}")
            return False # Abortar se um artefato falhar

        if not install_model_artifact(download_destination, target_path_in_container, model_version_manifest):
            logging.error(f"Falha ao instalar o artefato do modelo: {filename}")
            return False
            
    logging.info(f"Modelo {model_name_manifest} versão {model_version_manifest} configurado com sucesso.")
    # Aqui, pode ser necessário um mecanismo para sinalizar ao container scene_summarizer para recarregar o modelo
    # ou para que o docker-compose o reinicie se o modelo for carregado na inicialização.
    # Ex: criar um arquivo "flag" que o healthcheck do scene_summarizer verifica.
    Path(MODELS_INSTALL_DIR / ".model_updated_flag").touch()
    return True

# No fluxo principal do bootstrap.py:
# if not setup_bitnet_model():
#     logging.critical("Falha crítica ao configurar o modelo BitNet. O sistema pode não funcionar corretamente.")
#     # Decidir se deve abortar o bootstrap
3.3. Modificações em summarize_scene.py
Carregar o modelo do caminho de instalação definido (e.g., /app/models/bitnet/ dentro do container, que mapeia para /opt/vv-video-ai-system/models/bitnet/ no host).
Logar a versão do modelo que está sendo carregada (lendo de .current_model_info.json ou um arquivo similar dentro da pasta do modelo).
3.4. docker-compose.yml para scene_summarizer
YAML
services:
  scene_summarizer:
    # ...
    volumes:
      - ./models:/app/models:ro # Montar o diretório de modelos como somente leitura
      # Ou se o bootstrap rodar fora do compose, o caminho já estará populado
      # e o Dockerfile do scene_summarizer pode copiar de um estágio de build
      # ou o bootstrap pode colocar os modelos em um volume nomeado.
      # Exemplo com volume nomeado (bootstrap precisaria saber este path):
      # - vv_models_volume:/app/models:ro
    # ...
# volumes:
#   vv_models_volume: # Definir o volume nomeado
Se o bootstrap.py roda no host antes do docker-compose up, ele populará ./models. Se bootstrap.py rodar dentro de um container do compose, ele precisará de acesso de escrita a um volume que o scene_summarizer depois monta como leitura.

4. Walkthrough de Atualização de Modelo
Novo Modelo Treinado/Convertido: Uma nova versão do BitNet (e.g., v1.1.0) está pronta.
Publicar Artefato: Faça upload do bitnet_summarizer_v1.1.0.tar.gz para o local de armazenamento (e.g., S3) e calcule seu SHA256.
Atualizar Manifesto: Crie uma nova versão do model_manifest.json (ou atualize-o) com os detalhes do v1.1.0 (nova URL, novo SHA256, nova versão "1.1.0").
JSON
{
  "model_name": "BitNet-4bit-Summarizer",
  "version": "1.1.0", 
  "artifacts": [
    {
      "filename": "bitnet_summarizer_v1.1.0.tar.gz",
      "url": "https://your-storage.example.com/models/bitnet_summarizer_v1.1.0.tar.gz",
      "sha256": "new_sha256_hash",
      "target_path_in_container": "/app/models/bitnet"
    }
  ]
}
Commit e Push do Manifesto: Faça commit e push do model_manifest.json atualizado para o repositório Git.
Acionar Atualização no Host:
Execute git pull no host do VV-Video-AI-System para obter o novo manifesto.
Execute python3 bootstrap.py (ou python3 update_model.py se separado).
O script deve detectar a nova versão, baixar, validar e instalar o modelo v1.1.0.
Reiniciar/Recarregar scene_summarizer:
Se o scene_summarizer não recarregar modelos automaticamente, reinicie o container: docker-compose restart scene_summarizer.
Verifique os logs do scene_summarizer para confirmar que ele carregou o modelo v1.1.0.
5. Impacto Esperado
Rastreabilidade: Claro entendimento de qual versão do modelo está em uso.
Consistência: Garante que todos os nós/instâncias usem a mesma versão do modelo.
Atualizações Controladas: Processo definido para implantar novos modelos.
Rollback Facilitado: Capacidade de reverter para uma versão anterior do modelo de forma controlada.
Melhoria da Manutenibilidade: Separa o gerenciamento do modelo do código da aplicação.